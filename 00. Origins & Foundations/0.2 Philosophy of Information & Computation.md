## Computation
- Before machines, there is meaning.
- Computing is a way of knowing.
	- A lens through which we interpret reality.
	- A method of structuring thought.
	- A framework for encoding, transforming and communicating information.

## The Role of Philosophy
- What is information?
	- Is it objective, subjective or relational?
- What is computation?
	- Is it mechanical symbol manipulation or is it identical with thought?
- Where are the boundaries?
	- What cannot be computed, represented or known?
- Engineers must know what is possible before building.
- Scientists must know what is measurable before claiming knowledge.
- Ethicists must know what is meaningful before deciding responsibility.

- Plato
	- Saw reality as structured by eternal forms — computation echoes this in abstraction
- Aristotle.
	- Formal logic {syllogisms} -> precursor to Boolean algebra and rule-based reasoning.
- Leibniz
	- Dreamed of a "calculus of reason" where disputes could be settled by calculation.
- Wiener
	- Cybernetics connected feedback, information and control across biology and machines.

## What is Information?
- Information is the reduction of uncertainly. It is what is conveyed or represented by a particular arrangement of elements — symbols, signals, states.

- **Claude Shannon's Model {1948}**
	- Outlines the process where a source sends a message through a transmitter, which converts it into a signal sent over a channel to a receiver, who then decodes it back into the original message.
	- Introduced the idea of information as the measurable structure in communication systems.
	- The amount of information is tied to how much uncertainty is reduced when a message is received.
	- The less predictable the choice, the more information it carries.
		- $H = -\sum_{i} p_i\log_2(p_i)$
			- H = entropy {average uncertainty} and $p_i$ = probability of symbol $i$.
			- Information is measured in bits and is independent of meaning. "colorless green ideas sleep furiously " has the same information as a random string of words, if probabilities match.
	- "Information is not meaning. It is pattern."
	- Popularized the concept of the "bit".

- What is a Bit?
	- Bit is a contraction of "binary digit", but its conceptual significance is more profound.
	- It represents the answer to a yes/no question. It is the atomic unit of uncertainty reduction — the smallest possible piece of information.
		- If you flip a coin and don't know the result, once you learn it was "heads", you've gained 1 bit of information.
	- The word "bit" was first used by John Turkey {a statistician}, but was popularized in computing through Shannon's work.
		- Shannon formalized the bit not as a mechanical switch or character, but as a unit of entropy — a unit of "choice", grounded in probability.
    - A bit does not contain semantic meaning on its own. "Yes" or "No" doesn't mean anything unless there's context.
    - The interpretation — the meaning — is assigned by humans or systems that understand the framework of symbols.
    - Thus, despite information being different from meaning, meaning emerges when we interpret patterns of information.
## Information as Meaning
- Engineers stopped at bits but philosophers pushed further.
- Gregory Bateson {1972}
	- "Information is a difference that makes a difference".
	- Focuses not on raw signals but on impact within a system.
- Floridi's Philosophy of Information {1999}
	- Defines information as well-formed, meaningful and truthful data.
	- Introduces levels of abstraction.
		- What counts as "information" depends on the observer and context.
- Semiotics {Peirce, Saussure}
	- Information as sign systems.
	- Every symbol has signifier {form}, signified {concept} and interpretant {effect on observer}

## Bits, Entropy and The Universe
- In physics, entropy is disorder but also information content.
- Rolf Landauer {1961} -> "Information is physical".
	- Erasing one bit of information has a thermodynamic cost (kT In 2) # check chat after cuz idk

## Conversation Theory
- Gordon Pask {1970}
	- Proposed that learning and communication are forms of computation.
	- Information is not static, it arises in dialogue between systems.
	- A conversation is computational when it updates the state of both participants.

## Computation
- At its core, computation is transformation.
	- The systematic manipulation of symbols, states or representations according to well-defined rules.
- However, "computation" depends on perspective.
	- Mathematical
		- Applying algorithms to input to produce output
	- Physical
		- State transitions in a material substrate {electrons, gears, neurons}
	- Philosophical
		- The embodiment of reasoning — a model of thought expressed mechanically

## Computation as Rule-Based Symbol Manipulation
- Formal view
	- A computation takes an initial configuration and applies a finite sequence of rules to reach a new configuration.
	- Arithmetic {example}
		- Start with symbols 2 and 2 -> apply the addition rule -> yield 4
- Computation does not require understanding — it only requires rule-following

## Computation as Physical Process
- Every computation is instantiated in matter.
	- Ancient tally sticks -> notches on bone
	- Mechanical calculators -> gears and levers
	- Digital computers -> transistors switching states
	- Neural networks -> weighted sums in silicon

## Computation as Cognition
- Computational Theory of Mind
	- Human thinking can be modeled as computational processes.
	- Neurons are the "hardware", thought are the "software".
- Critiques
	- Human cognition involves qualia, intuition and creativity that may not reduce to rule-following.
- Middle ground
	- Even if humans are more than computers, computation provides the most powerful model of reasoning we have.

## Syntactic vs. Semantic Computation
- Syntactic
	- Computers operate on symbol form only.
	- $1010$ is just a pattern of states.
- Semantic
	- Meaning emerges when humans or systems interpret that pattern as $10$ in decimal or as "line break" in ASCII
- Computation by itself is blind. Interpretation gives it purpose.

## Information $\neq$ Knowledge
- Computation begins with data but humans live in the realm of knowledge.
- Data
	- Raw symbols, numbers or signals.
- Information
	- Data organized in a way that reduces uncertainty.
- Knowledge
	- Interpreted information, situated in context and validated as truth.
- Wisdom
	- The capacity to apply knowledge responsibly with judgment and foresight.

## From Data to Information
- Data -> $01000001$
- Information -> Interpreted as "A" in ASCII
- Knowledge -> "A" is the first letter of the alphabet
- Wisdom -> Letters from language, language conveys thought

- Each step adds layers of meaning and purpose.
- A database may store accurate data.
- A program may transform it into information.
- However, only humans can frame it as knowledge and apply it as wisdom.

## The Ontology of Computation
- Computation seems abstract.
	- Symbols on paper
	- Logical rules
	- Equations
- Every act of computation has always been tied to matter and energy.
- Is computation merely a model of thought or is it a real process of the universe?

## Landauer's Principle

- Proposed by Rold Landauer at IBM.
- States
	- Erasing one bit of information releases a minimum amount of heat
		- You cannot separate computation from physics.
		- Bits are not free.
		- Every calculation carries an energy cost.

## Views on Computation
- Nominalistic
	- Computation is a human construct.
	- A convenient way to describe processes.
	- It has no independent existence outside our interpretation.
- Realistic
	- Information and computation exist independently.
		- Numbers in mathematics.
	- DNA sequences, black holes and weather systems all "compute" regardless of human labeling.
- Pancomputationalistic
	- Everything in the universe is a computation process
	- Atoms, cells and galaxies can be seen as information processors.
	- The universe itself is a computer.

## Computation and Physics
- Thermodynamics
	- Energy cost of information links computing to entropy.
- Quantum mechanics
	- Quantum bits show that information can exist in superpositions and entangled states.
- Cosmology
	- Some theories suggest black hole "store" information in surface area {holographic principle}

## DNA as Computation
- DNA encodes instructions using four bases (A, T, C, G).
- Ribosomes "compute" proteins by translationg these sequences into amino acids.
- No abstraction layer is needed — biological computation in matter.

